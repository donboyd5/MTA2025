---
output: html_document
editor_options: 
  chunk_output_type: console
---

# County Business Patterns (CBP)

CBP links

-   [landing page](https://www.census.gov/programs-surveys/cbp.html)
-   [csv data files](https://www.census.gov/data/datasets/2022/econ/cbp/2022-cbp.html)
-   [county file for 2022](https://www2.census.gov/programs-surveys/cbp/datasets/2022/cbp22co.zip)

## Setup

```{r}
#| label: setup
#| include: false

source(here::here("R", "libraries.r"))
source(here::here("R", "libraries_ts.r"))
source(here::here("R", "constants.r"))
source(here::here("R", "functions.r"))

```

## Get data

```{r}
#| label: get-data
#| output: false

fpath <- fs::path(PDRAW, "cbp", "cbp22co.zip")
cbp1 <- vroom(fpath, col_types = cols(.default = col_character()))
glimpse(cbp1)

fpath <- fs::path(PDRAW, "cbp", "georef22.txt")
areas <- vroom(fpath, col_types = cols(.default = col_character()))
glimpse(areas)

areas2 <- areas |>
  separate(col = county_name, 
           into = c("county", "state"), 
           sep = ",(?=[^,]*$)", 
           extra = "merge") |> 
  mutate(state=ifelse(fipstate=="35" & fipscty=="013",
                      "New Mexico",
                      str_trim(state)),
         county=ifelse(fipstate=="35" & fipscty=="013",
                       "Doña Ana County",
                       county))

fpath <- fs::path(PDRAW, "cbp", "naics2017.txt")
inds <- vroom(fpath, col_types = cols(.default = col_character()), 
              delim=",",
              locale = locale(encoding = "Windows-1252")) |> 
  rename_with(str_to_lower)
glimpse(inds)

inds2 <- inds |> 
  mutate(description=str_remove_all(description, "’"))


# character columns
# FIPSTATE        C       FIPS State Code
# FIPSCTY         C       FIPS County Code
# NAICS           C       Industry Code - 6-digit NAICS code.
# EMP_NF          C       Total Mid-March Employees Noise Flag (See all Noise Flag definitions at the end of this record layout)
# QP1_NF          C       Total First Quarter Payroll Noise Flag
# AP_NF           C       Total Annual Payroll Noise Flag

# Noise Flag definitions (fields ending in _NF) are:
#         G       0 to < 2% noise (low noise)
#         H       2 to < 5% noise (medium noise)
#         J	>= 5% noise (high noise)
# Flag definition for Establishment by Employment Size Class fields (N<5, N5_9, etc.):
#         N	Not available or not comparable

# Noteworthy variables:
#   NAICS           C       Industry Code - 6-digit NAICS code.
#   EMP             N       Total Mid-March Employees with Noise
#   QP1             N       Total First Quarter Payroll ($1,000) with Noise
#   AP              N       Total Annual Payroll ($1,000) with Noise
#   EST             N       Total Number of Establishments
#   N1000           N       Number of Establishments: 1,000 or More Employee Size Class
#   N1000_1         N       Number of Establishments: Employment Size Class: 1,000-1,499 Employees

```

```{r}
#| label: clean-cbp

char_cols <- c("fipstate", "fipscty", "naics", "emp_nf", "qp1_nf", "ap_nf")

# put state and county names on the data

cbp2 <- cbp1 |> 
  mutate(across(-all_of(char_cols), as.numeric)) |> 
  rename(nlt_5=`n<5`) |> 
  left_join(areas2 |> 
              select(fipstate, fipscty, state, county),
            by = join_by(fipstate, fipscty)) |> 
  left_join(inds, join_by(naics))
glimpse(cbp2)
count(cbp2, state) # 51: 50 + DC
count(cbp2, county) # 1,882
count(cbp2 |> filter(state=="New York"), county) # 63: 62 + Statewide

cbp3 <- cbp2 |> 
  filter(state=="New York") |> 
  mutate(mta=paste0(fipstate, fipscty) %in% constants$mtafips,
         nyc=paste0(fipstate, fipscty) %in% constants$nycfips)
count(cbp3, mta, nyc, county)

saveRDS(cbp3, fs::path(PDINTERMEDIATE, "cbpny.rds"))

```

```{r}
#| label: cbp-explore

cbpny <- readRDS(fs::path(PDINTERMEDIATE, "cbpny.rds"))
skim(cbpny)

cbpny2 <- cbpny |> 
  mutate(across(where(is.numeric), ~replace_na(., 0))) |> 
  mutate(estsum=rowSums(across(nlt_5:n1000)),
         nmiss=est - estsum,
         misspct=nmiss / est)
skim(cbpny2)

cbpny2 |> 
  filter(misspct > .9, mta) |> 
  select(state, county, naics, ap, est, estsum, nmiss, misspct, description) |> 
  summary()

tmp <- cbpny2 |> 
  mutate(diff=est - estsum, pdiff=diff / est) |> 
  select(state, county, naics, ap, est, estsum, diff, pdiff, description, mta) |> 
  arrange(desc(abs(diff))) |> 
  filter(mta)

tmp |> 
  summarise(aptot=sum(ap),
            badap=sum(ap * (abs(diff) > 3))) |> 
  mutate(badpct=badap / aptot)

#        aptot     badap badpct
#        <dbl>     <dbl>  <dbl>
# 1 3220151436 757583639  0.235

bad <- cbpny2 |> 
  filter(misspct > .5, misspct < 1) |> 
  mutate(avgemp = emp / est) |> 
  relocate(avgemp, .after=emp)
  # mutate(across(nlt_5:n1000, \(x) x / est)) |> 
  # select(fipstate, fipscty, state, county, mta, nyc, naics, description, emp, ap, est, nlt_5:n1000) |> 

shares <- cbpny2 |> 
  mutate(across(nlt_5:n1000, \(x) x / est)) |> 
  select(fipstate, fipscty, state, county, mta, nyc, naics, description, emp, ap, est, nlt_5:n1000) |> 
  pivot_longer(nlt_5:n1000, values_to = "share") |> 
  mutate(share_adj=share / sum(share), 
         .by=c(fipstate, fipscty, naics))

skim(shares)

bad <- shares |> 
  filter(is.na(share_adj)) |> 
  filter(name=="nlt_5") |> 
  select(-c(name:share_adj))

cbpny2 |> 
  filter(fipscty=="109",
         str_starts(naics, "61"),
         estsum==0) |> 
  select(county, naics, emp_nf:n1000, estsum, description) |> 
  mutate(avgemp=emp / est) |> 
  relocate(avgemp, .after=est)
  arrange(desc(emp))
# maybe put all bad estabs in the size group for their average?
  
# Create sample data frame
df <- tibble::tibble(
  x = 1:5,
  y = 6:10
)

# Define function that returns multiple variables
calc_stats <- function(x) {
  tibble::tibble(
    doubled = x * 2,
    squared = x^2,
    plus_ten = x + 10
  )
}

df |> 
  mutate(across(x, ~calc_stats(.x), .unpack = TRUE))


```


## Allocate missing estabs and then compute shares

put the unallocated estabs into the group that has varage employment

```{r}
#| label: allocate

avgemp1 <- read_csv("
name, lb, ub
nlt_5, 0, 4
n5_9, 5, 9
n10_19, 10, 19
n20_49, 20, 49
n50_99, 50, 99
n100_249, 100, 249
n250_499, 250, 499
n500_999, 500, 599
n1000, 1000, 1000")
avgemp1

shares <- cbpny2 |> 
  select(fipstate, fipscty, state, county, mta, nyc, naics, description, emp, ap, est, nmiss, nlt_5:n1000) |> 
  pivot_longer(nlt_5:n1000, values_to = "known") |> 
  left_join(avgemp1, by = join_by(name)) |> 
  mutate(avgemp1=case_when(name=="n1000" ~ 0,
                           .default = (lb + ub) / 2),
         emp1 = known * avgemp1) |> 
  mutate(empsum1 = sum(emp1),
         diff1=emp - empsum1[name=="n1000"],
         avgdiff1=ifelse(name=="n1000", diff1 / known, NA_real_),
         .by=c(fipstate, fipscty, naics)) 
  # we want every emp amount in each range to fall within its bounds, and the total to hit the known employment
shares


tmp <- shares |> 
  filter(nmiss > 5)

tmp |> filter(fipscty=="047", naics=="484121")

# optimize using data for 36, 001, ------

library(CVXR)

avgemp <- (lb + ub) / 2
empestimated <- estknown * avgemp
(sumempestimated <- sum(empestimated)) # 178480

emp <- 176385
estknown <- c(4686, 1769, 1272, 1001, 369, 224, 40, 24, 9) # 9 groups
lb <- c(0, 5, 10, 20, 50, 100, 250, 500, 1000) # 9 groups
ub <- c(4, 9, 19, 49, 99, 249, 499, 599, 1e9) # 9 groups

 #             [,1]
 # [1,]    4.000001
 # [2,]    9.000000
 # [3,]   16.702829
 # [4,]   21.224774
 # [5,]   57.577232
 # [6,]  100.000000
 # [7,]  499.000000
 # [8,]  599.000000
 # [9,] 2360.666517


# allocate emp to the groups st each > lb, < ub, min diff from avg emp ^ 2
# Your data
emp <- 176385
estknown <- c(4686, 1769, 1272, 1001, 369, 224, 40, 24, 9)
lb <- c(0, 5, 10, 20, 50, 100, 250, 500, 1000)
ub <- c(4, 9, 19, 49, 99, 249, 499, 599, 1e9)

# Define variables
x <- Variable(9)

# Define objective function directly within CVXR
objective <- Minimize(sum_squares(x * estknown - emp))

# Define constraints
constraints <- list(
    x >= lb,
    x <= ub,
    sum(x * estknown) == emp  # Add constraint to ensure total matches
)

# Solve the problem
prob <- Problem(objective, constraints)
result <- solve(prob)

# Get solution
solution <- result$getValue(x)

sum(as.vector(solution) * estknown)


## version 2 ----
fvec <- function(vec) cat("c(", paste0(vec, collapse=", "), ")", sep="")

v2 <- shares |> 
  filter(fipscty=="047", naics=="484121")
v2
v2$emp[1]
v2$est[1]
fvec(v2$known)
fvec(v2$lb)

emp <- 879
est <- 461
estknown <- c(444, 11, 0, 0, 0, 0, 0, 0, 0)
lb <- c(0, 5, 10, 20, 50, 100, 250, 500, 1000)
ub <- c(4, 9, 19, 49, 99, 249, 499, 599, 1e9)

# Define variables
estabs <- Variable(9)
avgemp <- Variable(9)

constraints <- list(
    avgemp >= lb,
    avgemp <= ub,
    sum(avgemp * estabs) == emp
)

objective <- Minimize(sum_squares(estabs - estknown))
prob <- Problem(objective, constraints)
result <- solve(prob)


# Define constraints
constraints <- list(
    x >= lb,
    x <= ub,
    sum(x * estknown) == emp  # Add constraint to ensure total matches
)

# Solve the problem
prob <- Problem(objective, constraints)
result <- solve(prob)

# Get solution
solution <- result$getValue(x)


# version 3 ----
fvec <- function(vec) cat("c(", paste0(vec, collapse=", "), ")", sep="")

v3 <- shares |> 
  filter(fipscty=="047", naics=="484121")
v3
v3$emp[1]
v3$est[1]
fvec(v3$known)
fvec(v3$lb)

emp <- 879
est <- 461
estknown <- c(444, 11, 0, 0, 0, 0, 0, 0, 0)
lb <- c(0, 5, 10, 20, 50, 100, 250, 500, 1000)
ub <- c(4, 9, 19, 49, 99, 249, 499, 599, 10000)

# Define objective function
obj <- function(params) {
    n <- length(estknown)
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    sum((estabs * avgemp - emp + estabs - estknown)^2)
    # sum((estabs * avgemp - emp)^2) + sum((estabs - estknown)^2)
}

# Initial values
n <- length(estknown)
start_params <- c(estknown, # initial estabs
                 (lb + ub)/2) # initial avgemp
obj(start_params)


# Define bounds
lower_bounds <- c(estknown, lb)
upper_bounds <- c(estknown[1:2], rep(Inf, 7), ub)
cbind(lower_bounds, start_params, upper_bounds)

# Solve
result <- nlminb(start_params, 
                 obj, 
                 lower = lower_bounds, 
                 upper = upper_bounds,
                 control=list(eval.max=5000,
                              iter.max=5000,
                              abs.tol=1e-20,
                              rel.tol=1e-12))
result

# Extract results
estabs_solution <- result$par[1:n]
avgemp_solution <- result$par[(n+1):(2*n)]

cbind(estknown, estabs_solution)
est; sum(estabs_solution)
emp; sum(estabs_solution * avgemp_solution)


result <- optim(start_params,
                obj,
                method = "L-BFGS-B", # only L-BFGS-B for these
                lower = lower_bounds,
                upper = upper_bounds)


# alabama YES! ----

library(alabama)
fvec <- function(vec) cat("c(", paste0(vec, collapse=", "), ")", sep="")

v3 <- shares |> 
  filter(fipscty=="047", naics=="484121")
v3
v3$emp[1]
v3$est[1]
fvec(v3$known)
fvec(v3$lb)

emp <- 879
est <- 461
estknown <- c(444, 11, 0, 0, 0, 0, 0, 0, 0)
lb <- c(0, 5, 10, 20, 50, 100, 250, 500, 1000)
ub <- c(4, 9, 19, 49, 99, 249, 499, 599, 100000)
avgb <- (lb + ub) / 2
n <- length(estknown)

# Define bounds
lower_bounds <- c(estknown, lb)
upper_bounds <- c(estknown[1:2], rep(Inf, 7), ub)
cbind(lower_bounds, start_params, upper_bounds)

start_params <- c(estknown, # initial estabs
                 (lb + ub)/2) # initial avgemp


obj <- function(params) {
    n <- length(estknown)
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    sum((estabs - estknown)^2)
}

gradient <- function(params) {
    n <- length(estknown)
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    
    # Initialize gradient vector
    grad <- numeric(2*n)
    
    # Gradient with respect to estabs
    grad[1:n] <- 2 * (estabs - estknown)
    
    # Gradient with respect to avgemp
    grad[(n+1):(2*n)] <- 0  # derivative is zero as avgemp doesn't appear in objective
    
    return(grad)
}


# Define separate constraint function
heq <- function(params) {
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    
    # Return vector of constraint values
    # Each element should be >= 0 for inequality constraints
    # or = 0 for equality constraints
    return(c(
        sum(estabs) - est,        # equality: sum(estabs) = est
        sum(estabs * avgemp) - emp  # equality: sum(estabs * avgemp) = emp
    ))
}

heq.jac <- function(params) {
    n <- length(params)/2
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    
    # Initialize Jacobian matrix (2 constraints x 2n variables)
    jacobian <- matrix(0, nrow = 2, ncol = 2*n)
    
    # Derivatives for first constraint: sum(estabs) - est
    jacobian[1, 1:n] <- 1        # d/d_estabs
    jacobian[1, (n+1):(2*n)] <- 0  # d/d_avgemp
    
    # Derivatives for second constraint: sum(estabs * avgemp) - emp
    jacobian[2, 1:n] <- avgemp         # d/d_estabs
    jacobian[2, (n+1):(2*n)] <- estabs # d/d_avgemp
    
    return(jacobian)
}

hin <- function(params) {
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    return(c(
      avgemp - lb,
      ub - avgemp
      ))
}

hin.jac <- function(params) {
    n <- length(params)/2
    estabs <- params[1:n]
    avgemp <- params[(n+1):(2*n)]
    
    # Initialize Jacobian matrix (2n constraints x 2n variables)
    jacobian <- matrix(0, nrow = 2*n, ncol = 2*n)
    
    # Derivatives for first n constraints: avgemp - lb
    jacobian[1:n, 1:n] <- 0                # d/d_estabs
    jacobian[1:n, (n+1):(2*n)] <- diag(n)  # d/d_avgemp
    
    # Derivatives for second n constraints: ub - avgemp
    jacobian[(n+1):(2*n), 1:n] <- 0                # d/d_estabs
    jacobian[(n+1):(2*n), (n+1):(2*n)] <- -diag(n) # d/d_avgemp
    
    return(jacobian)
}



result <- auglag(par = start_params,
                fn = obj,
                gr = gradient,
                heq = heq,
                heq.jac = heq.jac,
                hin = hin,
                hin.jac = hin.jac)

# Extract results
estabs_solution <- result$par[1:n]
avgemp_solution <- result$par[(n+1):(2*n)]

cbind(estknown, estabs_solution) |> kable()
cbind(lb, avgemp_solution, ub) |> kable()
est; sum(estabs_solution)
emp; sum(estabs_solution * avgemp_solution)
# calc max avg emp for top group

library(microbenchmark)
speed <- microbenchmark(
  auglag(par = start_params,
                fn = obj,
                heq = constraint_fun),
  auglag(par = start_params,
                fn = obj,
                gr = gradient,
                heq = constraint_fun,
                heq.jac = jacobian_constraint),
  times=100
)

speed



# END alabama ----

cbpny2

shares <- cbpny2 |> 
  mutate(across(nlt_5:n1000, \(x) x / est)) |> 
  select(fipstate, fipscty, state, county, mta, nyc, naics, description, emp, ap, est, nlt_5:n1000) |> 
  pivot_longer(nlt_5:n1000, values_to = "share") |> 
  mutate(share_adj=share / sum(share), 
         .by=c(fipstate, fipscty, naics))
```

